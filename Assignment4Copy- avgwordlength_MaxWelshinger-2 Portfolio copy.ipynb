{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average word length application**\n",
    "\n",
    "### Write a MapReduce program using PySpark that reads any text inputs and computes the average length of all words that start with each character.\n",
    "#### For any text input, the job should report the average length of words that starts with \"a\", \"b\" and so forth. \n",
    "\n",
    "For example, given the text input that include two sentences:\n",
    "\"No now is definitely not the time to call them\"\n",
    "\n",
    "\"This new device is helping American cut their power bills in half\"\n",
    "\n",
    "Output would be:\n",
    "\n",
    "[('a', 8.0),\n",
    " ('b', 5.0),\n",
    " ('c', 3.5),\n",
    " ('d', 8.0),\n",
    " ('h', 5.5),\n",
    " ('i', 2.0),\n",
    " ('n', 2.75),\n",
    " ('p', 5.0),\n",
    " ('t', 3.67)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 1: Creating a base RDD and pair RDDs **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a base RDD with `parallelize` and using pair RDDs to count words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Create a base RDD **\n",
    "#### We'll start by generating a base RDD by using a Python list and the `sc.parallelize` method.  Then we'll print out the type of the base RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n",
      "['cat', 'elephant', 'rat', 'Rout', 'Catch']\n"
     ]
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'Rout', 'Catch']\n",
    "# set number of partitions to be 4.\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "# Print out the type of wordsRDD\n",
    "print(type(wordsRDD))\n",
    "print(wordsRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Lowercase and test **\n",
    "#### We apply a map() transformation to lowercase each string in wordsRDD we just created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'elephant', 'rat', 'rout', 'catch']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowerWordsRDD = wordsRDD.map(lambda x : x.lower())\n",
    "lowerWordsRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Length of each word **\n",
    "#### Now use `map()` and a `lambda` function to return the number of characters in each word.  We'll `collect` this result directly into a variable wordLengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 8, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "wordLengths = (lowerWordsRDD\n",
    "                 .map(lambda x: len(x))\n",
    "                 .collect())\n",
    "print(wordLengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **First character of each word **\n",
    "#### Now use `map()` and a `lambda` function to return the first characters of the words.  We'll `collect` this result directly into a variable firstChar. Given a string s, you can use s[0] to obtain the first chacter of the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c', 'e', 'r', 'r', 'c']\n"
     ]
    }
   ],
   "source": [
    "firstChars = (lowerWordsRDD\n",
    "                 .map(lambda s: s[0])\n",
    "                 .collect())\n",
    "print(firstChars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **charPairRDDs **\n",
    "#### The next step, we want to combine previous steps. We create a new type of RDD, called charPairRDD. A charPairRDD is an RDD where each element is a pair tuple `(k, v)` where `k` is the key and `v` is the value. In this example, we will create a pair consisting of `('<first character>', <word length>)` for each word in the lowerWordsRDD.\n",
    "#### We can create the charPairsRDD using the `map()` transformation with a `lambda()` function to create a new RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('c', 3), ('e', 8), ('r', 3), ('r', 4), ('c', 5)]\n"
     ]
    }
   ],
   "source": [
    "charPairRDD = lowerWordsRDD.map(lambda x: (x[0], len(x)))\n",
    "print(charPairRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Part 2: Computing average word lengths with charPairRDDs **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let's compute the average word length giving a particular character in the RDD. There are multiple ways to perform this computation, but some are much less efficient than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing avg word length using `groupByKey`, which is easier to understand but not as efficient as using reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: [3, 5]\n",
      "r: [3, 4]\n",
      "e: [8]\n"
     ]
    }
   ],
   "source": [
    "charsGrouped = charPairRDD.groupByKey()\n",
    "for key, value in charsGrouped.collect():\n",
    "    print('{0}: {1}'.format(key, list(value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2a.1) Compute sum of word lengths\n",
    "#### For example, given the key/value pair ('c', [3,5]), where [3,5] represents the wordlengths of the two words (i.e, cat and catch) that starts with 'c', write code to output ('c', 8), where 8 is the sum of [3,5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('c', 8), ('r', 7), ('e', 8)]\n"
     ]
    }
   ],
   "source": [
    "wordLengthRDD = charsGrouped.map(lambda x: (x[0], sum(x[1])))\n",
    "print(wordLengthRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting by value\n",
    "####  Since we want to compute average word lengths, we need to count number of words that starts with a given charater. So for the key/value pair ('c', [3,5]), write code to output ('c', 2), where 2 is the count of items in the list [3,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 2), ('r', 2), ('e', 1)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCountRDD= charsGrouped.map(lambda x: (x[0], len(x[1])))\n",
    "wordCountRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After knowing how to compute word counts and word lengths, we can now write code to compute average word count. Apply the map or mapValues function with a lambda function to charsGrouped and obtain an RDD avgWordLengths that contains a list of key/value pairs. Each key represents a character, and the value the average word length of words that start with the character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 4.0), ('r', 3.5), ('e', 8.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgWordLengths = charsGrouped.mapValues(lambda x: sum(x)/len(x))\n",
    "avgWordLengths.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2b) A better approach is to start from the pair RDD and then use the [reduceByKey()](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey) transformation to create a charPairRDD. The `reduceByKey()` transformation gathers together pairs that have the same key and applies the function provided to two values at a time, iteratively reducing all of the values to a single value. `reduceByKey()` operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', (3, 1)), ('e', (8, 1)), ('r', (3, 1)), ('r', (4, 1)), ('c', (5, 1))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morecharPairRDD = charPairRDD.mapValues(lambda x: (x,1))\n",
    "morecharPairRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create sumCountPairRDD. Each pair in the RDD consists of  `('<first character>', (<sum of word lengths>, <word count>))` - the value of the pair is a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', (8, 2)), ('r', (7, 2)), ('e', (8, 1))]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumCountPairRDD = morecharPairRDD.reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\n",
    "sumCountPairRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will create an RDD called avgWordLengths. Each pair in the RDD consists of `('<first character>', <avg word length>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c', 4.0), ('r', 3.5), ('e', 8.0)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgWordLengths = sumCountPairRDD.mapValues(lambda x: x[0] / x[1])\n",
    "avgWordLengths.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  All together \n",
    "#### The code below performs a sequence of transformations to wordsRDD that contains a list of words to output average word lengths using reduceByKey. These transformations are included in just one statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('c', 4.0), ('e', 8.0), ('r', 3.5)]\n"
     ]
    }
   ],
   "source": [
    "avgWordLengthsCollected = (wordsRDD\n",
    "                           .map(lambda x: x.lower())\n",
    "                           .map(lambda x: (x[0], len(x)))\n",
    "                           .mapValues(lambda x: (x,1))\n",
    "                           .reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\n",
    "                           .mapValues(lambda x: x[0] / x[1])\n",
    "                           .mapValues(lambda x: round(x, 2))\n",
    "                           .sortByKey()\n",
    "                           .collect())\n",
    "print(avgWordLengthsCollected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Apply avg word lengths to a file **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this section we will finish developing our average word length application.  We'll have to build the `avgWordLength` function that can be used to deal with real world datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** `avgWordLength` function **\n",
    "#### First, define a function for average word length.  This function should take in an RDD that is a list of words like `wordsRDD` and return a RDD that includes key/value pairs. Each key represent a lowercase character and each value represent average length of words that start with the charactors. The values should be rounded to two decimal places. The key value pairs should be sorted by key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('c', 4.0), ('e', 8.0), ('r', 3.5)]\n"
     ]
    }
   ],
   "source": [
    "def avgWordLength(wordListRDD):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        wordListRDD (RDD of str): An RDD consisting of words.\n",
    "\n",
    "    Returns:\n",
    "        RDD of (str, int): An RDD consisting of (character, avgwordlength) tuples.\n",
    "    \"\"\"\n",
    "    resultRDD = (wordListRDD\n",
    "                 .map(lambda x: x.lower())\n",
    "                 .map(lambda x: (x[0], len(x)))\n",
    "                 .mapValues(lambda x: (x,1))\n",
    "                 .reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "                 .mapValues(lambda x: x[0] / x[1])\n",
    "                 .mapValues(lambda x: round(x, 2))\n",
    "                 .sortByKey()\n",
    "                )\n",
    "    return resultRDD\n",
    "                 \n",
    "print(avgWordLength(wordsRDD).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Remove punctuation ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi you\n",
      "No underscore\n"
     ]
    }
   ],
   "source": [
    "def removePunctuation(text):\n",
    "    \"\"\"\n",
    "    Note:\n",
    "        Only spaces, letters, and numbers should be retained.  Other characters should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "\n",
    "    Args:\n",
    "        text (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned up string.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    import string\n",
    "    text= text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return re.sub(r'[^\\w\\s]','',text).strip()\n",
    "print(removePunctuation('Hi, you!'))\n",
    "print(removePunctuation(' No under_score!'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Load a text file **\n",
    "#### For the next part of this lab, we will use the [Complete Works of William Shakespeare](http://www.gutenberg.org/ebooks/100) from [Project Gutenberg](http://www.gutenberg.org/wiki/Main_Page). To convert a text file into an RDD, we use the `SparkContext.textFile()` method. We also apply the recently defined `removePunctuation()` function using a `map()` transformation to strip out the punctuation.  Since the file is large we use `take(15)`, so that we only print 15 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: Project Gutenbergs The Complete Works of William Shakespeare by William\n",
      "2: Shakespeare\n",
      "3: \n",
      "4: This eBook is for the use of anyone anywhere in the United States and\n",
      "5: most other parts of the world at no cost and with almost no restrictions\n",
      "6: whatsoever  You may copy it give it away or reuse it under the terms\n",
      "7: of the Project Gutenberg License included with this eBook or online at\n",
      "8: wwwgutenbergorg  If you are not located in the United States youll\n",
      "9: have to check the laws of the country where you are located before using\n",
      "10: this ebook\n",
      "11: \n",
      "12: See at the end of this file  CONTENT NOTE added in 2017\n",
      "13: \n",
      "14: \n"
     ]
    }
   ],
   "source": [
    "shakespeareRDD = (sc\n",
    "                  .textFile(\"shakespeare.txt\", 8)\n",
    "                  .map(removePunctuation))\n",
    "print('\\n'.join(shakespeareRDD\n",
    "                .zipWithIndex()  # to (line, lineNum)\n",
    "                .map(lambda x: '{0}: {1}'.format(x[1], x[0]))  # to 'lineNum: line'\n",
    "                .take(15))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (3d) Apply a transformation that will split each element (i.e., sentence) of the shakespeareRDD by its spaces. For each element of the RDD, apply Python's string [split()](https://docs.python.org/2/library/string.html#string.split) function. Use flatMap(). If we do a split of an empty line, we are going to get an empty list. flatMap() will automatically remove these emtpy lists. As a result, the RDD you obtained from the funtion flatMap() does not contain any empty elements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zwounds', 'zwounds', 'zwaggered', 'zone', 'zodiacs']\n"
     ]
    }
   ],
   "source": [
    "shakespeareWordsRDD = shakespeareRDD.flatMap(lambda x: x.split())\n",
    "print(shakespeareWordsRDD.top(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** Compute the average word lengths **\n",
    "#### We now have an RDD that is only words.  Next, let's apply the `avgWordLength()` function to produce a list of key/value pairs with lowercase characters as the keys and average word lengths as the values. We can view the top 15 words by using the `takeOrdered()` action; however, since the elements of the RDD are pairs, we need a custom sort function that sorts using the value part of the pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1', 2.58), ('2', 1.63), ('3', 1.58), ('4', 1.74), ('5', 2.26), ('6', 2.42), ('7', 2.56), ('8', 2.6), ('9', 2.62), ('a', 3.28), ('b', 4.49), ('c', 6.25), ('d', 4.99), ('e', 5.51), ('f', 4.92), ('g', 5.21), ('h', 4.0), ('i', 2.21), ('j', 5.26), ('k', 4.73), ('l', 4.72), ('m', 3.97), ('n', 3.81), ('o', 2.86), ('p', 6.28), ('q', 5.9), ('r', 6.03), ('s', 4.98), ('t', 3.83), ('u', 4.6), ('v', 5.89), ('w', 4.43), ('x', 2.5), ('y', 3.53), ('z', 5.17)]\n"
     ]
    }
   ],
   "source": [
    "avgWordLengthRDD = avgWordLength(shakespeareWordsRDD)\n",
    "print(avgWordLengthRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 6.28\n",
      "c: 6.25\n",
      "r: 6.03\n",
      "q: 5.9\n",
      "v: 5.89\n",
      "e: 5.51\n",
      "j: 5.26\n",
      "g: 5.21\n",
      "z: 5.17\n",
      "d: 4.99\n",
      "s: 4.98\n",
      "f: 4.92\n",
      "k: 4.73\n",
      "l: 4.72\n",
      "u: 4.6\n"
     ]
    }
   ],
   "source": [
    "#Take top 15 characters with the largest average word lengths\n",
    "\n",
    "top15CharaterWithAvgWordLengths = avgWordLengthRDD.takeOrdered(15, key = lambda x: -x[1])\n",
    "print ('\\n'.join(map(lambda w_c: '{0}: {1}'.format(w_c[0], w_c[1]), top15CharaterWithAvgWordLengths)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
